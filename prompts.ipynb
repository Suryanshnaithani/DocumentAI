{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ebf83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import json\n",
    "import fitz \n",
    "import os\n",
    "import tempfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d18aa419",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=genai.Client(api_key=os.getenv(\"gemini_api\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a30697",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "C:\\\\Users\\\\surya\\\\AppData\\\\Local\\\\Temp\\\\pdf_pages_melr2x2o\\\\page_1.pdf is not a valid file path.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m file=\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43msurya\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mAppData\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mLocal\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mTemp\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mpdf_pages_melr2x2o\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mpage_1.pdf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\surya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\genai\\files.py:624\u001b[39m, in \u001b[36mFiles.upload\u001b[39m\u001b[34m(self, file, config)\u001b[39m\n\u001b[32m    622\u001b[39m fs_path = os.fspath(file)\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fs_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isfile(fs_path):\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a valid file path.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    625\u001b[39m file_obj.size_bytes = os.path.getsize(fs_path)\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file_obj.mime_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: C:\\\\Users\\\\surya\\\\AppData\\\\Local\\\\Temp\\\\pdf_pages_melr2x2o\\\\page_1.pdf is not a valid file path."
     ]
    }
   ],
   "source": [
    "file=client.files.upload(file=r\"C:\\\\Users\\\\surya\\\\AppData\\\\Local\\\\Temp\\\\pdf_pages_melr2x2o\\\\page_1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815d07b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"\"\"You are an advanced OCR (Optical Character Recognition) engine. Your task is to perform a full-fledged, page-wise transcription of the provided document with the highest possible accuracy and without any hallucinations.\n",
    "Instructions:\n",
    "Page-by-Page Processing: Process the document strictly on a page-by-page basis. Each page's extracted text should be clearly delineated and indexed by its corresponding page number.\n",
    "Comprehensive Text Extraction: Extract all textual content from each page, including:\n",
    "Main body text\n",
    "Headers and footers\n",
    "Text within tables\n",
    "Captions for images and figures\n",
    "Footnotes and endnotes\n",
    "Text within graphical elements (if legible)\n",
    "Structured Output Format: Present the output in a structured format, preferably JSON, with a clear hierarchy. Each page object should contain its full text content. For example:\n",
    "code\n",
    "JSON\n",
    "{\n",
    "  \"page\": [\n",
    "    {\n",
    "      \"content\": \"[Full text content of page]\"\n",
    "    }\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "Preserve Original Formatting (as much as possible):\n",
    "Maintain the original paragraph breaks.\n",
    "Recognize and transcribe lists (numbered and bulleted) accurately.\n",
    "For tabular data, attempt to preserve the row and column structure within the text output, using clear delimiters like \" | \" for cells and newlines for rows.\n",
    "Highest Accuracy and No Hallucinations:\n",
    "Transcribe the text exactly as it appears in the document.\n",
    "Do not infer, guess, or add any information that is not explicitly present in the source document.\n",
    "If a word or character is illegible or unclear, represent it with a specific placeholder (e.g., [ILLEGIBLE]). Do not attempt to guess the content.\n",
    "Pay close attention to special characters, symbols, and diacritics, and transcribe them accurately.\n",
    "Language and Character Set:\n",
    "The document is primarily in English. Be prepared to handle any other languages or special character sets, e.g., mathematical equations, chemical formulas if they appear.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e045044",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt_2=\"\"\"You are an advanced OCR (Optical Character Recognition) engine. Your task is to perform a full-fledged, page-wise transcription of the provided document with the highest possible accuracy and without any hallucinations.\n",
    "Instructions\n",
    "1. Page-by-Page Processing\n",
    "Process the document strictly on a page-by-page basis. Each page's extracted text should be clearly delineated and indexed by its corresponding page number.\n",
    "2. Comprehensive Text Extraction\n",
    "Extract all textual content from each page, including but not limited to:\n",
    "Main body text\n",
    "Headers and footers\n",
    "Text within tables\n",
    "Captions for images and figures\n",
    "Footnotes and endnotes\n",
    "Text within graphical elements (if legible)\n",
    "3. Structured Output Format\n",
    "Present the output in a structured JSON format with a clear hierarchy. Each page object should contain its full text content.\n",
    "Example JSON Structure:\n",
    "code\n",
    "JSON\n",
    "{\n",
    "  \"page\": [\n",
    "    {\n",
    "      \"content\": \"[Full text content of page]\"\n",
    "    }\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "4. Preserve Original Formatting (as much as possible)\n",
    "Formatting Element\tInstruction\n",
    "Paragraphs\tMaintain the original paragraph breaks.\n",
    "Lists\tRecognize and transcribe lists (numbered and bulleted) accurately.\n",
    "Tabular Data\tAttempt to preserve the row and column structure within the text output, using clear delimiters like \" | \" for cells and newlines for rows.\n",
    "5. Highest Accuracy and No Hallucinations\n",
    "Transcribe the text exactly as it appears in the document.\n",
    "Do not infer, guess, or add any information that is not explicitly present in the source document.\n",
    "If a word or character is illegible or unclear, represent it with a specific placeholder (e.g., [ILLEGIBLE]). Do not attempt to guess the content.\n",
    "Pay close attention to special characters, symbols, and diacritics, and transcribe them accurately.\n",
    "6. Language and Character Set\n",
    "The primary language of the document is English. Be prepared to handle any other languages or special character sets, such as mathematical equations or chemical formulas, if they appear.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db5f647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_prompt=\"\"\"You are an advanced OCR (Optical Character Recognition) engine. Your primary task is to transcribe the provided document into a single Markdown file. The goal is to ensure the rendered Markdown file visually imitates the original document's layout, structure, and formatting as perfectly as possible.\n",
    "Core Instructions\n",
    "Page-by-Page Processing: Transcribe the document sequentially, page by page. \n",
    "\n",
    "\n",
    "\n",
    "Comprehensive Text Extraction: You must extract all textual content from each page, including headers, footers, main body text, table content, captions, and footnotes.\n",
    "\n",
    "No Hallucinations: Transcribe the text exactly as it appears. Do not infer, guess, or add information that is not explicitly present. If a word or character is illegible, represent it with the placeholder [ILLEGIBLE].\n",
    "\n",
    "\n",
    "## 3. STRUCTURAL & FORMATTING RULES\n",
    "\n",
    "You **must** use the following Markdown syntax to represent the corresponding document elements:\n",
    "\n",
    "| Document Element          | Markdown Implementation                                                                                                                  |\n",
    "| :------------------------ | :--------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Headings**              | Use appropriate heading levels (`#`, `##`, `###`, etc.) to match the visual hierarchy of titles and subtitles.                               |\n",
    "| **Paragraphs**            | Preserve original paragraph breaks with a blank line between them.                                                                       |\n",
    "| **Bold & Italics**        | Use `**bold text**` for bolded text and `*italicized text*` for italics or underlined text.                                                 |\n",
    "| **Lists**                 | Replicate numbered (`1.`, `2.`) and bulleted (`*`, `-`) lists exactly, including any indentation for nested items.                         |\n",
    "| **Tables**                | Reconstruct tables using Markdown's native pipe syntax. **Do not use HTML (`<table>`, `<tr>`, `<td>`).**                                   |\n",
    "| **Headers & Footers**     | Place header/footer text at the very top/bottom of each page's section, separated from the main content by a horizontal rule (`---`).       |\n",
    "| **Image/Figure Placeholders** | Represent images or figures with a descriptive placeholder like `[IMAGE: A bar chart showing quarterly profits]`.                     |\n",
    "| **Captions**              | Place captions directly below their corresponding placeholder and format them in italics (e.g., `*Figure 1: Quarterly Profit Growth.*`).      |\n",
    "| **Footnotes**             | Use Markdown footnote syntax: place `[^1]` in the text and define the footnote `[^1]: Footnote text here.` at the bottom of the page section. |\n",
    "| **Blockquotes**           | For indented blocks of text or quotes, use the blockquote symbol (`>`).                                                                  |\n",
    "| **Code / Preformatted Text** | Use triple backticks (```) to enclose blocks of code or preformatted text.                                                                |\n",
    "\n",
    "Response format:\n",
    "\n",
    "JSON\n",
    "{\n",
    "  \"page\": [\n",
    "    {\n",
    "      \"content\": \"[Full text content of page]\"\n",
    "    }\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d4250902",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[file],\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_prompt,\n",
    "        temperature=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "491b98fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(json_output: str):\n",
    "    # Parsing out the markdown fencing\n",
    "    lines = json_output.splitlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if line == \"```json\":\n",
    "            json_output = \"\\n\".join(lines[i+1:]) \n",
    "            json_output = json_output.split(\"```\")[0]  \n",
    "            break  \n",
    "    return json_output\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "116dcadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_pdf_to_pages(pdf_path: str) -> dict[int, str]:\n",
    "    \"\"\"\n",
    "    Splits a PDF into individual one-page PDFs.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to the input PDF file.\n",
    "        \n",
    "    Returns:\n",
    "        dict[int, str]: A dictionary mapping page_number -> single-page PDF file path.\n",
    "    \"\"\"\n",
    "    # Creates a temporary directory to store the split pages\n",
    "    output_dir = tempfile.mkdtemp(prefix=\"pdf_pages_\")\n",
    "\n",
    "    # Opens the original PDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page_dict = {}\n",
    "\n",
    "    # Iterates through each page\n",
    "    for page_num in range(len(doc)):\n",
    "        single_page_doc = fitz.open()         # create a new empty PDF\n",
    "        single_page_doc.insert_pdf(doc, from_page=page_num, to_page=page_num)\n",
    "\n",
    "        # Construct the output file path\n",
    "        output_path = os.path.join(output_dir, f\"page_{page_num+1}.pdf\")\n",
    "        single_page_doc.save(output_path)\n",
    "        single_page_doc.close()\n",
    "\n",
    "        # Stores in dictionary (1-based page number)\n",
    "        page_dict[page_num + 1] = output_path\n",
    "\n",
    "    doc.close()\n",
    "    return page_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3bc4bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_test=r\"C:\\Users\\surya\\OneDrive\\Desktop\\Projects\\DocumentAI\\Test_docs\\brochure.pdf\"\n",
    "page_dict=split_pdf_to_pages(file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e3a30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16065b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing page: 1\n",
      "Parsing page: 2\n",
      "Parsing page: 3\n",
      "Parsing page: 4\n",
      "Parsing page: 5\n",
      "Parsing page: 6\n",
      "Parsing page: 7\n",
      "Parsing page: 8\n",
      "Parsing page: 9\n",
      "Parsing page: 10\n",
      "Parsing page: 11\n",
      "OCR data saved to: ocr_output_new.json\n"
     ]
    }
   ],
   "source": [
    "all_page_data=[]\n",
    "\n",
    "for page_number, page_path in page_dict.items():\n",
    "    print(\"Parsing page:\",page_number)\n",
    "    file=client.files.upload(file=page_path)\n",
    "    response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[file],\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=ocr_prompt,\n",
    "        temperature=0\n",
    "    )\n",
    ")\n",
    "    data={\"page_number\":page_number,\"ocr\": None}\n",
    "    # Parsing the model's response\n",
    "    parsed_data = parse_json(response.text)\n",
    "    if parsed_data:\n",
    "        try:\n",
    "            # If parse_json is dict \n",
    "            if isinstance(parsed_data, dict):\n",
    "                json_data = parsed_data\n",
    "            else:\n",
    "                # If it is a string\n",
    "                safe_str = re.sub(r'[\\x00-\\x1F\\x7F]', ' ', parsed_data)\n",
    "                json_data = json.loads(safe_str)\n",
    "\n",
    "                # json_data = json.loads(parsed_data)\n",
    "\n",
    "            data[\"ocr\"] = json_data.get(\"page\", [{}])[0].get(\"content\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing page {page_number}: {e}\")\n",
    "\n",
    "    all_page_data.append(data)\n",
    "\n",
    "output_json_path = \"ocr_output_new.json\"\n",
    "with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_page_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"OCR data saved to: {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6f581d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RERA Registration No. UPRERAPRJ250823/04/2025\n",
      "dated 30-04-2025 (website: www.up-rera.in)\n",
      "\n",
      "GODREJ MAJESTY\n",
      "SECTOR 12, GREATER NOIDA (W)\n",
      "\n",
      "FOR YOUR EXCELLENCE\n",
      "\n",
      "Godrej PROPERTIES\n",
      "\n",
      "Godrej Properties Limited (CIN- L74120MH1985PLC035308) (\"Company\") is developing a residential group housing project Godrej Majesty\n",
      "(\"Project\"), situated at Plot No. GH-01/B,C,D,E.J and K, Sec 12, Gr. Noida, which is registered with Uttar Pradesh Real Estate Regulatory\n",
      "Authority vide RERA Registration No. UPRERAPRJ250823/04/2025 dated 30/04/25 (website: www.up-rera.in). The Project is being developed,\n",
      "pursuant to permit no. SM-10-Dec-2024:23309 dated 16/02/25 valid for 5 years granted by Gr. Noida Authority for the Project and any further\n",
      "revisions and renewals in future. The terms of allotment/sale shall be subject to documents executed with the Company and approvals\n",
      "(as renewed time to time).\n"
     ]
    }
   ],
   "source": [
    "print(parsed_data[\"page\"][0][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30ef87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2=\"gemini-2.5-flash-lite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b7347e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt_2=\"\"\"You are an advanced Document Layout Analysis engine. Your primary function is to interpret the structural layout of a document page.\n",
    "You will be given the raw text content of a document, organized by page number (the output from a high-accuracy OCR process). Your task is to analyze this text in the context of a document's visual structure and generate a detailed, structured JSON output that identifies, chunks, and provides precise bounding boxes for every significant element on each page.\n",
    "Instructions:\n",
    "Input: Your input will be a JSON object containing the page-wise text content. It will follow this format:\n",
    "code\n",
    "JSON\n",
    "{\n",
    "  \"document_title\": \"Example Document\",\n",
    "  \"total_pages\": 1,\n",
    "  \"pages\": [\n",
    "    {\n",
    "      \"page_number\": 1,\n",
    "      \"content\": \"Document Title\\n\\nThis is the first paragraph of the document. It contains several sentences to illustrate a block of text.\\n\\nAnother Paragraph\\nThis is the second paragraph. It follows the first one after a clear separation.\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "Core Task: Identify and Chunk Elements: For each page, analyze its content to identify and segment distinct logical blocks. You must identify the following element types:\n",
    "Headings: (e.g., heading_1, heading_2)\n",
    "Paragraphs: (paragraph)\n",
    "Tables: (table)\n",
    "Lists: and their individual items (list, list_item)\n",
    "Images: (image) - Note: You won't have the image data, but you should infer its location based on surrounding text like captions or empty space in the layout.\n",
    "Captions: (caption)\n",
    "Headers: (header)\n",
    "Footers: (footer)\n",
    "Page Numbers: (page_number)\n",
    "Bounding Box Generation: For every element you identify, you must provide its precise location and dimensions on the page.\n",
    "Coordinate System: The origin (0, 0) is the top-left corner of the page.\n",
    "Units: Specify the units for the bounding box coordinates (e.g., pixels, points). Assume a standard page dimension if not specified (e.g., 8.5x11 inches at 96 DPI).\n",
    "Format: The bounding box must be represented as [x_min, y_min, x_max, y_max].\n",
    "Structured Output Format: Your final output must be a single JSON object. For each page, provide a list of \"elements,\" where each element is an object containing its type, its text content (if applicable), and its bounding box.\n",
    "Highest Accuracy and No Hallucinations:\n",
    "Do not invent elements. Your analysis must be based on the logical and structural flow of the provided text.\n",
    "Do not guess bounding boxes. The coordinates must be geometrically accurate. If the exact position of an element cannot be determined, do not create an entry for it.\n",
    "Ensure that bounding boxes for different elements do not improperly overlap (e.g., a header's box should not contain a main paragraph's box).\n",
    "Example of Desired Output:\n",
    "Based on the example input above, the ideal output would be:\n",
    "code\n",
    "JSON\n",
    "{\n",
    "  \"document_layout\": [\n",
    "    {\n",
    "      \"page_number\": 1,\n",
    "      \"dimensions\": {\n",
    "        \"width\": 816,\n",
    "        \"height\": 1056,\n",
    "        \"unit\": \"pixels\"\n",
    "      },\n",
    "      \"elements\": [\n",
    "        {\n",
    "          \"type\": \"heading_1\",\n",
    "          \"content\": \"Document Title\",\n",
    "          \"bounding_box\": [100, 80, 716, 120]\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"paragraph\",\n",
    "          \"content\": \"This is the first paragraph of the document. It contains several sentences to illustrate a block of text.\",\n",
    "          \"bounding_box\": [100, 150, 716, 220]\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"heading_2\",\n",
    "          \"content\": \"Another Paragraph\",\n",
    "          \"bounding_box\": [100, 250, 716, 280]\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"paragraph\",\n",
    "          \"content\": \"This is the second paragraph. It follows the first one after a clear separation.\",\n",
    "          \"bounding_box\": [100, 290, 716, 340]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c42c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bounding_box_system_instructions = \"\"\"\n",
    "    Return bounding boxes as a JSON array with labels. Never return masks or code fencing. Limit to 25 objects.\n",
    "    If an object is present multiple times, name them according to their unique characteristic (colors, size, position, unique characteristics, etc..).\n",
    "\"\"\"\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22480e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    contents=[file,data,sys_prompt_2],\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=bounding_box_system_instructions,\n",
    "        temperature=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eda97f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=parse_json(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdbcd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parsed_data = json.loads(new_data)\n",
    "\n",
    "with open(\"output.json\", \"w\", encoding=\"utf-8\") as dump_file:\n",
    "    json.dump(parsed_data, dump_file, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2ecfaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import tempfile\n",
    "import fitz\n",
    "import concurrent.futures\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Gemini client\n",
    "client = genai.Client(api_key=os.getenv(\"gemini_api\"))\n",
    "\n",
    "\n",
    "def parse_json(json_output: str):\n",
    "    \"\"\"\n",
    "    Extracts JSON content from Gemini response by removing ```json fences.\n",
    "    \"\"\"\n",
    "    lines = json_output.splitlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip() == \"```json\":\n",
    "            json_output = \"\\n\".join(lines[i + 1:])\n",
    "            json_output = json_output.split(\"```\")[0]\n",
    "            break\n",
    "    return json_output\n",
    "\n",
    "\n",
    "def split_pdf_to_pages(pdf_path: str) -> dict[int, str]:\n",
    "    \"\"\"\n",
    "    Splits a PDF into individual one-page PDFs.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the input PDF file.\n",
    "\n",
    "    Returns:\n",
    "        dict[int, str]: A mapping of page numbers to temporary single-page PDF paths.\n",
    "    \"\"\"\n",
    "    output_dir = tempfile.mkdtemp(prefix=\"pdf_pages_\")\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page_dict = {}\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        single_page_doc = fitz.open()\n",
    "        single_page_doc.insert_pdf(doc, from_page=page_num, to_page=page_num)\n",
    "        output_path = os.path.join(output_dir, f\"page_{page_num + 1}.pdf\")\n",
    "        single_page_doc.save(output_path)\n",
    "        single_page_doc.close()\n",
    "        page_dict[page_num + 1] = output_path\n",
    "\n",
    "    doc.close()\n",
    "    return page_dict\n",
    "\n",
    "\n",
    "def ocr_single_pdf(pdf_path: str, ocr_prompt: str, output_dir: str):\n",
    "    \"\"\"\n",
    "    Performs OCR on a single PDF using Gemini and saves JSON + Markdown outputs.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "        ocr_prompt (str): OCR instruction prompt.\n",
    "        output_dir (str): Directory to save results.\n",
    "\n",
    "    Returns:\n",
    "        tuple[str, str]: Paths to JSON and Markdown outputs.\n",
    "    \"\"\"\n",
    "    pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    pdf_output_dir = os.path.join(output_dir, pdf_name)\n",
    "    os.makedirs(pdf_output_dir, exist_ok=True)\n",
    "\n",
    "    page_dict = split_pdf_to_pages(pdf_path)\n",
    "    all_page_data = []\n",
    "    markdown_output = []\n",
    "\n",
    "    for page_number, page_path in page_dict.items():\n",
    "        print(f\"[{pdf_name}] Processing page {page_number}...\")\n",
    "        file = client.files.upload(file=page_path)\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            contents=[file],\n",
    "            config=types.GenerateContentConfig(\n",
    "                system_instruction=ocr_prompt,\n",
    "                temperature=0\n",
    "            )\n",
    "        )\n",
    "\n",
    "        data = {\"page_number\": page_number, \"ocr\": None}\n",
    "        parsed_data = parse_json(response.text)\n",
    "\n",
    "        if parsed_data:\n",
    "            try:\n",
    "                if isinstance(parsed_data, dict):\n",
    "                    json_data = parsed_data\n",
    "                else:\n",
    "                    safe_str = re.sub(r'[\\x00-\\x1F\\x7F]', ' ', parsed_data)\n",
    "                    json_data = json.loads(safe_str)\n",
    "\n",
    "                content = json_data.get(\"page\", [{}])[0].get(\"content\", \"\")\n",
    "                data[\"ocr\"] = content\n",
    "                markdown_output.append(f\"## Page {page_number}\\n\\n{content}\\n\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[{pdf_name}] Error parsing page {page_number}: {e}\")\n",
    "\n",
    "        all_page_data.append(data)\n",
    "\n",
    "    json_path = os.path.join(pdf_output_dir, f\"{pdf_name}_ocr.json\")\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_page_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    md_path = os.path.join(pdf_output_dir, f\"{pdf_name}_ocr.md\")\n",
    "    with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# OCR Compiled Output\\n\\n\" + \"\\n\".join(markdown_output))\n",
    "\n",
    "    print(f\"[{pdf_name}] Completed. JSON: {json_path}, Markdown: {md_path}\")\n",
    "    return json_path, md_path\n",
    "\n",
    "\n",
    "def ocr_folder_multithread(folder_path: str, output_dir: str = \"ocr_results\", max_threads: int = 4):\n",
    "    \"\"\"\n",
    "    Processes all PDFs in a folder concurrently using multiple threads.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to folder containing PDFs.\n",
    "        ocr_prompt (str): Instruction prompt for Gemini OCR.\n",
    "        output_dir (str): Directory where all outputs will be stored.\n",
    "        max_threads (int): Number of concurrent OCR threads.\n",
    "\n",
    "    Returns:\n",
    "        list[tuple[str, str]]: List of tuples containing JSON and Markdown output paths for each PDF.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    pdf_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.lower().endswith(\".pdf\")]\n",
    "\n",
    "    if not pdf_files:\n",
    "        print(\"No PDF files found in the given folder.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Found {len(pdf_files)} PDFs. Starting OCR with {max_threads} threads...\\n\")\n",
    "\n",
    "    results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "        futures = {\n",
    "            executor.submit(ocr_single_pdf, pdf, ocr_prompt, output_dir): pdf\n",
    "            for pdf in pdf_files\n",
    "        }\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            pdf_name = os.path.basename(futures[future])\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "                print(f\"[{pdf_name}] OCR completed successfully.\")\n",
    "            except Exception as e:\n",
    "                print(f\"[{pdf_name}] Error during OCR: {e}\")\n",
    "\n",
    "    print(\"\\nAll OCR tasks completed.\")\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88ac1fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 PDFs. Starting OCR with 4 threads...\n",
      "\n",
      "[brochure] Processing page 1...\n",
      "[brochure_2] Processing page 1...\n",
      "[OCCUPATION CERTIFICATE] Processing page 1...\n",
      "[brochure_2] Processing page 2...\n",
      "[brochure] Processing page 2...\n",
      "[OCCUPATION CERTIFICATE] Processing page 2...\n",
      "[brochure_2] Processing page 3...\n",
      "[brochure] Processing page 3...\n",
      "[OCCUPATION CERTIFICATE] Completed. JSON: ocr_results\\OCCUPATION CERTIFICATE\\OCCUPATION CERTIFICATE_ocr.json, Markdown: ocr_results\\OCCUPATION CERTIFICATE\\OCCUPATION CERTIFICATE_ocr.md\n",
      "[OCCUPATION CERTIFICATE.pdf] OCR completed successfully.\n",
      "[brochure] Processing page 4...\n",
      "[brochure_2] Processing page 4...\n",
      "[brochure] Processing page 5...\n",
      "[brochure_2] Processing page 5...\n",
      "[brochure] Processing page 6...\n",
      "[brochure] Processing page 7...\n",
      "[brochure] Processing page 8...\n",
      "[brochure_2] Processing page 6...\n",
      "[brochure] Processing page 9...\n",
      "[brochure_2] Processing page 7...\n",
      "[brochure] Processing page 10...\n",
      "[brochure_2] Processing page 8...\n",
      "[brochure] Processing page 11...\n",
      "[brochure] Completed. JSON: ocr_results\\brochure\\brochure_ocr.json, Markdown: ocr_results\\brochure\\brochure_ocr.md\n",
      "[brochure.pdf] OCR completed successfully.\n",
      "[brochure_2] Processing page 9...\n",
      "[brochure_2] Processing page 10...\n",
      "[brochure_2] Processing page 11...\n",
      "[brochure_2] Completed. JSON: ocr_results\\brochure_2\\brochure_2_ocr.json, Markdown: ocr_results\\brochure_2\\brochure_2_ocr.md\n",
      "[brochure_2.pdf] OCR completed successfully.\n",
      "\n",
      "All OCR tasks completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ocr_results\\\\OCCUPATION CERTIFICATE\\\\OCCUPATION CERTIFICATE_ocr.json',\n",
       "  'ocr_results\\\\OCCUPATION CERTIFICATE\\\\OCCUPATION CERTIFICATE_ocr.md'),\n",
       " ('ocr_results\\\\brochure\\\\brochure_ocr.json',\n",
       "  'ocr_results\\\\brochure\\\\brochure_ocr.md'),\n",
       " ('ocr_results\\\\brochure_2\\\\brochure_2_ocr.json',\n",
       "  'ocr_results\\\\brochure_2\\\\brochure_2_ocr.md')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "folder_path = r\"C:\\Users\\surya\\OneDrive\\Desktop\\Projects\\DocumentAI\\Test_docs\"\n",
    "ocr_folder_multithread(folder_path, max_threads=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
